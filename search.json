[
  {
    "objectID": "Definitions2.html",
    "href": "Definitions2.html",
    "title": "ChatRegs23",
    "section": "",
    "text": "section: Definitions contents: - text: “”\nsection: “Artificial intelligence” contents: - text: Artificial intelligence (AI) refers to an engineered system that generates predictive outputs such as content, forecasts, recommendations or decisions for a given set of human-defined objectives or parameters without explicit programming. AI systems are designed to operate with varying levels of automation.” - text: “Source” href: https://www.iso.org/obp/ui/#iso:std:iso-iec:22989:ed-1:v1:en\nsection: “Machine learning” contents: - text: “Machine learning are the patterns derived from training data using machine learning algorithms, which can be applied to new data for prediction or decision-making purposes” - text: “Source” href: https://www.iso.org/obp/ui/#iso:std:iso-iec:22989:ed-1:v1:en\nsection: Generative AI models contents: - text: “Generative AI models generate novel content such as text, images, audio and code in response to prompts.” - text: “Source” href: https://www.chiefscientist.gov.au/GenerativeAI%5d\nsection: Large Language Model (LLM) contents: - text: “A large language model (LLM) is a type of generative AI that specialises in the generation of human-like text.” - text: “Source” href: https://www.chiefscientist.gov.au/GenerativeAI%5d\nsection: Multimodal Foundation Model (MfM) contents: - text: “A Multimodal Foundation Model (MfM) is a type of generative AI that can process and output multiple data types (e.g. text, images, audio).” - text: “Source” href: https://www.chiefscientist.gov.au/GenerativeAI%5d\nsection: Automated Decision Making (ADM) contents: - text: “““Automated Decision Making (ADM) refers to the application of automated systems in any part of the decision-making process. Automated decision making includes using automated systems to:\n\nmake the final decision\nmake interim assessments or decisions leading up to the final decision\nrecommend a decision to a human decision-maker\nguide a human decision-maker through relevant facts, legislation or policy\nautomate aspects of the fact-finding process which may influence an interim decision or the final decision.\n\nAutomated systems range from traditional non-technological rules-based systems to specialised technological systems which use automated tools to predict and deliberate.”“” - text: “Source” href: https://www.ombudsman.gov.au/__data/assets/pdf_file/0029/288236/OMB1188-Automated-Decision-Making-Report_Final-A1898885.pdf\n\nAustralia’s AI Ethics Principles\nsection: “Human, societal and environmental wellbeing” contents: - text: “AI systems should benefit individuals, society and the environment.” - text: “Source” href: https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-framework/australias-ai-ethics-principles#principles-in-detail-3\nsection: “Human-centered values” contents: - text: “AI systems should respect human rights, diversity, and the autonomy of individuals.” - text: “Source” href: https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-framework/australias-ai-ethics-principles#principles-in-detail-3\nsection: “Fairness” contents: - text: “AI systems should be inclusive and accessible, and should not involve or result in unfair discrimination against individuals, communities or groups.” - text: “Source” href: https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-framework/australias-ai-ethics-principles#principles-in-detail-3\nsection: “Privacy protection and security” contents: - text: “AI systems should respect and uphold privacy rights and data protection, and ensure the security of data.” - text: “Source” href: https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-framework/australias-ai-ethics-principles#principles-in-detail-3\nsection: Reliability and safety contents: - text: “AI systems should reliably operate in accordance with their intended purpose.” - text: “Source” href: https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-framework/australias-ai-ethics-principles#principles-in-detail-3\nsection: Transparency and explainability contents: - text: “There should be transparency and responsible disclosure so people can understand when they are being significantly impacted by AI, and can find out when an AI system is engaging with them.” - text: “Source” href: https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-framework/australias-ai-ethics-principles#principles-in-detail-3\nsection: “Contestability” contents: - text: “When an AI system significantly impacts a person, community, group or environment, there should be a timely process to allow people to challenge the use or outcomes of the AI system.” - text: “Source” href: https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-framework/australias-ai-ethics-principles#principles-in-detail-3\nsection: “Accountability” contents:\n- text: “People responsible for the different phases of the AI system lifecycle should be identifiable and accountable for the outcomes of the AI systems, and human oversight of AI systems should be enabled.” - text: “Source” href: https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-framework/australias-ai-ethics-principles#principles-in-detail-3"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Definitions.html",
    "href": "Definitions.html",
    "title": "ChatRegs23",
    "section": "",
    "text": "Definitions\n::: g-col-3 ::: {.callout-note title=“Artificial intelligence” collapse=“true”} Artificial intelligence (AI) refers to an engineered system that generates predictive outputs such as content, forecasts, recommendations or decisions for a given set of human-defined objectives or parameters without explicit programming. AI systems are designed to operate with varying levels of automation. Source :::\n\n\n\n\n\n\nMachine learning\n\n\n\n\n\nMachine learning are the patterns derived from training data using machine learning algorithms, which can be applied to new data for prediction or decision-making purposes. Source\n\n\n\n\n\n\n\n\n\nGenerative AI models\n\n\n\n\n\nGenerative AI models generate novel content such as text, images, audio and code in response to prompts. Source\n\n\n\n\n\n\n\n\n\nLarge Language Model (LLM)\n\n\n\n\n\nA large language model (LLM) is a type of generative AI that specialises in the generation of human-like text. Source\n\n\n\n\n\n\n\n\n\nMultimodal Foundation Model (MfM)\n\n\n\n\n\nA Multimodal Foundation Model (MfM) is a type of generative AI that can process and output multiple data types (e.g. text, images, audio). Source\n\n\n\n\n\n\n\n\n\nAutomated Decision Making (ADM)\n\n\n\n\n\nAutomated Decision Making (ADM) refers to the application of automated systems in any part of the decision-making process. Automated decision making includes using automated systems to:\n\nmake the final decision\nmake interim assessments or decisions leading up to the final decision\nrecommend a decision to a human decision-maker\nguide a human decision-maker through relevant facts, legislation or policy\nautomate aspects of the fact-finding process which may influence an interim decision or the final decision.\n\nAutomated systems range from traditional non-technological rules-based systems to specialised technological systems which use automated tools to predict and deliberate. Source :::Í\n\nAustralia’s AI Ethics Principles\n\n\n\n\n\n\nHuman, societal and environmental wellbeing:\n\n\n\n\n\nAI systems should benefit individuals, society and the environment. Detail\n\n\n\n\n\n\n\n\n\nHuman-centred values\n\n\n\n\n\nAI systems should respect human rights, diversity, and the autonomy of individuals. Detail\n\n\n\n\n\n\n\n\n\nFairness\n\n\n\n\n\nAI systems should be inclusive and accessible, and should not involve or result in unfair discrimination against individuals, communities or groups. Detail\n\n\n\n\n\n\n\n\n\nPrivacy protection and security\n\n\n\n\n\nAI systems should respect and uphold privacy rights and data protection, and ensure the security of data. Detail\n\n\n\n\n\n\n\n\n\nReliability and safety\n\n\n\n\n\nAI systems should reliably operate in accordance with their intended purpose. Detail\n\n\n\n\n\n\n\n\n\nTransparency and explainability\n\n\n\n\n\nThere should be transparency and responsible disclosure so people can understand when they are being significantly impacted by AI, and can find out when an AI system is engaging with them. Detail\n\n\n\n\n\n\n\n\n\nContestability\n\n\n\n\n\nWhen an AI system significantly impacts a person, community, group or environment, there should be a timely process to allow people to challenge the use or outcomes of the AI system. Detail\n\n\n\n\n\n\n\n\n\nAccountability\n\n\n\n\n\nPeople responsible for the different phases of the AI system lifecycle should be identifiable and accountable for the outcomes of the AI systems, and human oversight of AI systems should be enabled. Detail"
  }
]